{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee621373-e01d-4d7f-8bc3-1b67d635b224",
   "metadata": {},
   "source": [
    "### Proof of Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a825c-0830-43ea-bff5-60f9544df259",
   "metadata": {},
   "source": [
    "Outline\n",
    "\n",
    "- import data / create dataloader classes\n",
    "- import text and vision model / create multimodal medvqa model that inherits from hf\n",
    "- import hf trainer and create model trainer that inherits from hf\n",
    "- train on base model / data, then fine tune model from checkpoint using anything (radiology in practice, slate for demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f5490-4bd9-44d8-b108-de88d3627231",
   "metadata": {},
   "source": [
    "Data:\n",
    "https://huggingface.co/datasets/xmcmic/PMC-VQA/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02162b70-a62f-47dd-b510-01cc7a63fc5e",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- bert tokenization of text in dataset wrapper\n",
    "- data augmentation python script\n",
    "\n",
    "- peft + clip models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d52c7640-119b-4508-9c5a-054fc7383f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from dataclasses import dataclass, field\n",
    "import transformers\n",
    "from transformers import AutoModel,BertConfig,AutoTokenizer,AutoProcessor,LlamaTokenizer, CLIPVisionModel, CLIPVisionConfig\n",
    "from torchvision import transforms\n",
    "from typing import Optional\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from peft import get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb979d2-3559-4b93-a12f-5eccae5f6d93",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a36ea6ce-25a6-4721-bf9d-4f280e0ba038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VQA Dataset\n",
    "\n",
    "class VQA_Dataset(Dataset):\n",
    "    def __init__(self, csv_path, img_root_dir, image_res, pretrained_tokenizer, is_train=True):\n",
    "        self.is_train = is_train\n",
    "        self.dataset = pd.read_csv(csv_path)\n",
    "        self.img_root_dir = img_root_dir\n",
    "        self.img_path_list = np.asarray(self.dataset['Figure_path'])\n",
    "        self.question_list = np.asarray(self.dataset['Question'])\n",
    "        self.choice_list = np.asarray(self.dataset.iloc[:,-5:-1])\n",
    "        self.answer_list = np.asarray(self.dataset['Answer'])\n",
    "        self.answer_label_list = np.asarray(self.dataset['Answer_label'])\n",
    "        \n",
    "        # initialize bert tokenizer + special tokens dict from pretrained llama model\n",
    "        self.tokenizer = LlamaTokenizer.from_pretrained(pretrained_tokenizer) # explore diff models - can fine-tune on medical but prob not too relevant\n",
    "        special_tokens_dict = {'mask_token': \"</s>\",\n",
    "                               'eos_token': \"</s>\",\n",
    "                               'bos_token': \"<s>\",\n",
    "                               'unk_token': \"<unk>\"}\n",
    "        self.tokenizer.add_special_tokens(special_tokens_dict)\n",
    "        self.tokenizer.pad_token_id=0\n",
    "    \n",
    "        # initialize, augment, and normalize torch img transformer\n",
    "        normalize = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        self.transform = transforms.Compose([                        \n",
    "                transforms.RandomResizedCrop([image_res,image_res],scale=(0.2, 1.0), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                #RandomAugment(2,7,isPIL=True,augs=['Identity','Equalize','Brightness','Sharpness', 'ShearX', 'ShearY', 'TranslateX', 'TranslateY', 'Rotate']),     \n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "    def encode_text(self, question_text, question_text_with_answer, mask_token= '</s>', pad_token='<unk>', eos_token = '</s>'):\n",
    "        # encode text using bert / llama tokenizer\n",
    "        return\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_root_dir, self.img_path_list[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "\n",
    "        question = self.question_list[idx]\n",
    "        answer = self.answer_list[idx]\n",
    "        answer_label = self.answer_label_list[idx]\n",
    "        choice_A = str(self.choice_list[idx][0])\n",
    "        choice_B = str(self.choice_list[idx][1])\n",
    "        choice_C = str(self.choice_list[idx][2])\n",
    "        choice_D = str(self.choice_list[idx][3])\n",
    "\n",
    "        return question, answer, image # should be dictionary of all values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "53a80299-eb05-466d-8bb4-c8ce99336c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model config\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    embed_dim: Optional[int] = field(default=768)\n",
    "    pretrained_tokenizer:  Optional[str] = field(default=\"TencentARC/LLaMA-Pro-8B\") # TBD\n",
    "    pretrained_model: Optional[str] = field(default=\"meta-llama/Llama-2-7b\")\n",
    "    image_encoder: Optional[str] = field(default=\"CLIP\")\n",
    "    # pmcclip_pretrained: Optional[str] = field(default=\"./models/pmc_clip/checkpoint.pt\")\n",
    "    clip_pretrained: Optional[str] = field(default=\"openai/clip-vit-base-patch32\")\n",
    "    # ckp: Optional[str] = field(default=\"./Results/VQA_lora_noclip/vqa/checkpoint-6500\")\n",
    "\n",
    "# data config\n",
    "@dataclass\n",
    "class DataArguments:\n",
    "    image_res: Optional[int] = field(default=512)\n",
    "    img_root_dir: str = field(default='images/')\n",
    "    Train_path: str = field(default='data/train.csv')\n",
    "    Test_path: str= field(default='data/test.csv')\n",
    "    \n",
    "# optimization, training data, etc.\n",
    "@dataclass\n",
    "class TrainingArguments(transformers.TrainingArguments):\n",
    "    output_dir: Optional[str] = field(default=\"results\")\n",
    "    cache_dir: Optional[str] = field(default=None)\n",
    "    optim: str = field(default=\"adamw_torch\")\n",
    "    logging_dir: Optional[str] = field(default=\"logs\")\n",
    "    logging_steps: Optional[int] = field(default=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0091c0e5-958d-40e4-9680-9738f98f6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = transformers.HfArgumentParser((ModelArguments, DataArguments, TrainingArguments))\n",
    "parser.add_argument(\"-f\", \"--file\", required=False)\n",
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses()[:3]\n",
    "\n",
    "Train_dataset = VQA_Dataset(data_args.Train_path, data_args.img_root_dir, data_args.image_res, model_args.pretrained_tokenizer, is_train=True)\n",
    "Test_dataset = VQA_Dataset(data_args.Test_path, data_args.img_root_dir, data_args.image_res, model_args.pretrained_tokenizer, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ab4839ca-6d8f-4cf4-bde2-e094d55dac46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the uptake pattern in the breast? ',\n",
       " 'Focal uptake pattern',\n",
       " tensor([[[-0.6623, -0.6281, -0.6452,  ...,  2.2318,  2.2318,  2.2318],\n",
       "          [-0.6452, -0.6281, -0.6452,  ...,  2.2318,  2.2318,  2.2318],\n",
       "          [-0.6281, -0.6452, -0.6623,  ...,  2.2318,  2.2318,  2.2318],\n",
       "          ...,\n",
       "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
       " \n",
       "         [[-0.5476, -0.5126, -0.5301,  ...,  2.4111,  2.4111,  2.4111],\n",
       "          [-0.5301, -0.5126, -0.5301,  ...,  2.4111,  2.4111,  2.4111],\n",
       "          [-0.5126, -0.5301, -0.5476,  ...,  2.4111,  2.4111,  2.4111],\n",
       "          ...,\n",
       "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
       " \n",
       "         [[-0.3230, -0.2881, -0.3055,  ...,  2.6226,  2.6226,  2.6226],\n",
       "          [-0.3055, -0.2881, -0.3055,  ...,  2.6226,  2.6226,  2.6226],\n",
       "          [-0.2881, -0.3055, -0.3230,  ...,  2.6226,  2.6226,  2.6226],\n",
       "          ...,\n",
       "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single training example\n",
    "Train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7511071f-4bee-4d45-b690-d353acf6a546",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "19b186d2-800e-464a-a1c8-019b2f2022cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert hyperparams\n",
    "@dataclass\n",
    "class CLIPconfig:\n",
    "    bert_model: str = field(default='dmis-lab/biobert-v1.1')\n",
    "    MOMENTUM: float = 0.5  # 0.99\n",
    "    \n",
    "# peft for fine tuning + lora\n",
    "@dataclass\n",
    "class PEFTconfig:\n",
    "    use_pretrained_peft: bool = field(default=True)\n",
    "    model: str = field(default='lora')\n",
    "    lora_rank: int = field(default=8) # dimension of low-rank matrices\n",
    "    lora_alpha: int = field(default=32) # scaling factor for the low-rank matrices\n",
    "    lora_dropout: int = field(default=0.1) # dropout probability of the LoRA layers\n",
    "    # num_virtual_tokens: int = field(default=32)\n",
    "    # mapping_hidden_dim: int = field(default=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "299561f2-7b0e-42bf-a522-55c12d8a3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peft_config(peft_args: PEFTconfig):\n",
    "    if peft_args.use_pretrained_peft:\n",
    "        peft_config = LoraConfig(\n",
    "            task_type = TaskType.CAUSAL_LM, inference_mode=False,\n",
    "            r = peft_args.lora_rank,\n",
    "            lora_alpha = peft_args.lora_alpha, \n",
    "            lora_dropout = peft_args.lora_dropout\n",
    "        )\n",
    "    else:\n",
    "        # TODO: lora fine tuning on text encoder for medical domain\n",
    "        # perf_config = ...\n",
    "        pass\n",
    "    return peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "447484e4-e3a1-4bbb-8220-b9aa8ff080c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = transformers.HfArgumentParser((CLIPconfig, PEFTconfig))\n",
    "parser.add_argument(\"-f\", \"--file\", required=False)\n",
    "clip_args, peft_args = parser.parse_args_into_dataclasses()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aa8258e6-bfe8-4cc0-9cbd-4d9eae13dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQA_Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(VQA_Model, self).__init__()\n",
    "        embed_dim = config.embed_dim\n",
    "        self.tokenizer = LlamaTokenizer.from_pretrained(config.pretrained_tokenizer)\n",
    "        self.llama_model = transformers.LlamaModel.from_pretrained(config.pretrained_model)\n",
    "        # peft_config = get_peft_config(PEFTconfig)\n",
    "        self.text_encoder = AutoTokenizer.from_pretrained(config.pretrained_tokenizer) # currently just biobert/tencent; TODO: change to peft model\n",
    "        self.text_embed = nn.Sequential(nn.Linear(4096, embed_dim))\n",
    "        \n",
    "        # clip vision encoder\n",
    "        if config.image_encoder == \"CLIP\":\n",
    "            self.image_encoder_name = \"CLIP\"\n",
    "            clip_config = CLIPVisionConfig(image_size=512)\n",
    "            self.image_encoder = CLIPVisionModel(clip_config).from_pretrained(config.clip_pretrained) # \"openai/clip-vit-base-patch32\"\n",
    "            self.image_encoder.vision_model.embeddings = transformers.models.clip.modeling_clip.CLIPVisionEmbeddings(clip_config)\n",
    "        else:\n",
    "            self.image_encoder_name = \"PMC_CLIP\"\n",
    "            # TODO: pmc clip handling...\n",
    "        # other hidden players\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6af1ce69-4b8a-4189-84b3-330bd2f7826d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to request access at https://huggingface.co/meta-llama/Llama-2-7b and pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:286\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-2-7b/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/utils/hub.py:430\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1368\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1367\u001b[0m     \u001b[38;5;66;03m# Repo not found => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1368\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1370\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1238\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1238\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1631\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1631\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1640\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:385\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 385\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:409\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    408\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 409\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:302\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    299\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m     )\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GatedRepoError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepoNotFound\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    305\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n",
      "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-65cb4117-124023ae6c4b12bf615c5016;0d440a6e-620b-45bf-aeb9-2386f85234ec)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b/resolve/main/config.json.\nRepo model meta-llama/Llama-2-7b is gated. You must be authenticated to access it.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mVQA_Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[104], line 6\u001b[0m, in \u001b[0;36mVQA_Model.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m      4\u001b[0m embed_dim \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39membed_dim\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m LlamaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(config\u001b[38;5;241m.\u001b[39mpretrained_tokenizer)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllama_model \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLlamaModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# peft_config = get_peft_config(PEFTconfig)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_encoder \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(config\u001b[38;5;241m.\u001b[39mpretrained_tokenizer) \u001b[38;5;66;03m# currently just biobert/tencent; TODO: change to peft model\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/modeling_utils.py:2600\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2599\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m-> 2600\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2601\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2604\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2608\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2609\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2610\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2614\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   2615\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/utils/hub.py:445\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    431\u001b[0m         path_or_repo_id,\n\u001b[1;32m    432\u001b[0m         filename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    443\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to request access at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and pass a token having permission to this repo either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to request access at https://huggingface.co/meta-llama/Llama-2-7b and pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`."
     ]
    }
   ],
   "source": [
    "model = VQA_Model(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fcfb35-a955-4562-a1d6-c924c71e5087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
